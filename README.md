# Gosznak ML Taks

## Задание 1: Структуры и алгоритмы
См. файл `Задание_1.ipynb`.

## Задание 2 ML\DL

### Организация кода
    ├── README.md             <- Инструкция.
    │
    ├── configs    <- Параметры для обучения
    │   ├── default.yaml         <- Параметры по умолчанию
    │   ├── training             <- Дополнительные параметры для задачи классификации/деноизинга 
    |
    ├── logs        <- TensorBoard логи и веса моделей
    ├── src        <- Код

### Системные требования
* OS: Ubuntu 16.04
* Python: 3.6+
* CUDA: 10.2
* [pipenv](https://github.com/pypa/pipenv) (`pip install pipenv`)

<!-- Обучение проводилось на Tesla V100 -->

### Установка
1. Скопировать репозиторий `git clone https://github.com/zakajd/audio-denoising.git && cd audio-denoising`
2. При использовании Anaconda/venv создать новое окружение `conda env create -n "audio-denoising"`
3. Выполнить `pipenv install --deploy --ignore-pipfile` для установки зависимостей


### Тестирование лучшей модели
* Загрузить веса моделей [audio_classification_weights.zip](LINK) [audio_denoising_weights.zip](LINK) в папку проекта
* Разархивировать их: `unzip audio_classification_weights.zip && unzip audio_denoising_weights.zip`
* Для инференса выполнить `python3 test.py --help`. 

### Описание решения
Для задачи классификации была использована классическая архитектура ResNet50. Первые эксперименты показали, что из-за искусственного характера наложенного шума, уже за 1 эпоху предобученная сеть получает точность 100% и дальнейшее обучение не имеет смысла.

Для задачи деноизинга была использована архитектура типа Unet с предобученным энкодером SeResNet50. Обучение с MSE в качестве лосса дало сглаженный результат, см. пример 1. Дообучение с L1 лоссом улучшило результат визуально, но сделало хуже по метрике, см. пример 2.